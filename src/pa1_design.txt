			+--------------------+
			|        CS 140      |
			| PROJECT 1: THREADS |
			|   DESIGN DOCUMENT  |
			+--------------------+
				   
---- GROUP ----

>> Fill in the names and email addresses of your group members.

FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>
FirstName LastName <email@domain.example>

---- PRELIMINARIES ----

>> If you have any preliminary comments on your submission, notes for the
>> TAs, or extra credit, please give them here.

>> Please cite any offline or online sources you consulted while
>> preparing your submission, other than the Pintos documentation, course
>> text, lecture notes, and course staff.
>> OUR priority-fifo did work in our phase 1 and we got 100 on autograder for that but in phase 3 it broke but our donation is working fine priority is working fine but during test main thread(testing thread) priority gets changed automatically and it makes little change in output not much some breckets on test names are misspelled other then that it works. we checked our code, flow, everything sooo many times.
>> Is it possible that we get score for ATLEAST priority-fifo as it was passed in phase 1&2 and originally it was part of phase 1 only.  
Citation: 
https://uchicago-cs.github.io/mpcs52030/p0.html

			     ALARM CLOCK
			     ===========

---- DATA STRUCTURES ----

>>  struct semaphore sleep_started;     	 /* semaphore for each thread to sleep/wakeup location: thread.h -> thread struct */
    int64_t wakeup_tick;                	 /* wake up time for sleeping thread location: thread.h -> thread struct */
    struct list_elem sleeping_elem;     	 /* list_elem for sleeping_threads_list location: thread.h -> thread struct */
    static struct list sleeping_thread_list;     /* List of processes in THREAD_BLOCKED state, that is, processes that are sleeping and blocked by semaphore. location: timer.c */

---- ALGORITHMS ----

>> As soon as current thread calls timer_sleep, it disables the interrupts to avoid race condition for globally shared sleeping threads list. Then from ticks argument and timer_ticks() we calculate wake_tick for current thread. We add current thread to sleeping thread list and assign wakeup_tick to thread->wakeup_tick. Then we perform sema_down on current thread which blocks the thread and schedules the next thread.

>> On each timer tick in timer_interrupt(), we check if there is any thread in sleeping thread list, if there is any then we check if any thread has wakeup_tick less than or equal to current tick time. If condition fulfills we perform sema_up on thread and remove that thread from sleeping thread list.     


>> to minimize the amount of time spent in the timer interrupt handler, we check if there is any thread sleeping 

---- SYNCHRONIZATION ----

>> To avoid race condition we have disabled the interrupts before we add thread to list and we again enable interrupts later

---- RATIONALE ----

>> We tried implementation without semaphore, in that we were planning to manually block and unblock threads when needed. But with semaphore approach, it became simpler and the code was modular. Accessing ready list in timer.c was a problem and we would have to write additional functions in thread.c and that would have complicated things. 

			 PRIORITY SCHEDULING
			 ===================

---- DATA STRUCTURES ----
>> thread.h > struct thread
>> struct list acquired_lock_list;     /* list of acquired locks */
>> struct lock *requested_lock;        /* pointer to lock that thread is waiting for */
>> int old_priority;                   /* old priority for priority inversion */
>> bool priority_changed;              /* check if orignal priority is changed */ 

>> synch.h > struct lock
>> int highest_priority;      		   /* priority of a current lock holder */
>> struct list_elem lock_elem;		   /* For acquired lock list in each thread */

>> synch.c > struct semaphore_elem
>> int priority;                       /* priority for each semaphore_elem */

acquired_lock_list :  Is used to keep track of multiple donation. Which priority to assign next is taken as the second highest 
element of this list.
requested_lock : Is used to keep track of the lock requested by the thread. This is used to implement nested donation.
old_priority : This is used to keep track of original priority of thread in case of priority inversion.
priority_changed : This is used to check if the original priority of thread is changed or not. This was 
required to implement priority-donate-lower.
highest_priority: This is used to keep track of the highest priority assigned to the lock holder currently.
lock_elem: This is used to add lock to the acquired_lock_list declared in thread struct.
priority(semaphore_elem) : To sort semaphores according to priority for priority cond_var test case. 

Nested Donation: lock->holder->requested_lock->holder->requested_lock->holder

---- ALGORITHMS ----

>> B3: How do you ensure that the highest priority thread waiting for
>> a lock, semaphore, or condition variable wakes up first?
>> Every thread in waiters list is sorted based on priority.

>> B4: Describe the sequence of events when a call to lock_acquire()
>> causes a priority donation.  How is nested donation handled?
>> check if the holder is there or not - if holder is not NULL check if it's priority is lower than current thread priority then donate priority to lock holder and lock as well. then add pointer of lock to current threads requested lock. then perform sema_down and add thread to waiters list. 
whenever sema_up is performed thread will start from lock_acquire and assign themselves to holder and remove pointer from requested lock 
>to perform nested donation we will check for the holder in loop of 0 to 8 (lock->holder->requested_lock->holder->requested_lock->holder) and keep donating as much depth we find.


>> B5: Describe the sequence of events when lock_release() is called
>> on a lock that a higher-priority thread is waiting for.
>> we set the holder to NULL then perform sema up so highest priority thread in waiters list will be unblocked. to check if there is multiple donations are there we check the list of acquired lock list and assign the next highest priority lock's priority to current thread. if there's no lock left in the list we reassign the old priority and disable the flag



---- SYNCHRONIZATION ----

>> B6: Describe a potential race in thread_set_priority() and explain
>> how your implementation avoids it.  Can you use a lock to avoid
>> this race?
>> we did not consider this in thread_set_priority as there is no global variables to be accessed

---- RATIONALE ----

>> B7: Why did you choose this design?  In what ways is it superior to
>> another design you considered?
>> we considered maintaining stack for list of priority donations on each thread but it was diffcult to maintain in case of multiple donations for same lock and same donations for multiple locks. so we switched to list of acquired locks which would have list of waiters and it would give enough information.
>> we also considered maintaining same kind of list for requested locks to maintain nested donation but later while implementing we realised that thread can only request one lock at a time as it will be blocked after that so we switched to pointer variable for requested lock.

			  ADVANCED SCHEDULER
			  ==================

---- DATA STRUCTURES ----
>> thread.h > struct thread 
int nice                           /* niceness of thread */
fixed_point_t recent_cpu           /* recent cpu utilisation of thread */

>> thread.c > global static variable
fixed_point_t load_avg			   /* to maintain load over kernel */

---- ALGORITHMS ----

>> C2: Suppose threads A, B, and C have nice values 0, 1, and 2.  Each
>> has a recent_cpu value of 0.  Fill in the table below showing the
>> scheduling decision and the priority and recent_cpu values for each
>> thread after each given number of timer ticks:


>> as ticks are less than 100 recent CPU and load_avg will be 0 as initialised and priorities we assumed will be 0 and same initially  
timer  recent_cpu    priority   thread
ticks   A   B   C   A   B   C   to run
-----  --  --  --  --  --  --   ------
 0    0    0   0   0   0   0    A
 4    4    1   2  62   61  59   A          
 8    8    1   2  61   61  59   A          
12    12   1   2  60   61  59   B          
16    12   5   2  60   60  59   B          
20    12   9   2  60   59  59   A          
24    16   9   2  59   59  59   A          
28    20   9   2  58   59  59   B          
32    20   13  2  58   58  59   C          
36    20   13  6  58   58  58   C          

>> C3: Did any ambiguities in the scheduler specification make values
>> in the table uncertain?  If so, what rule did you use to resolve
>> them?  Does this match the behavior of your scheduler?
>> initial priority was not mentioned 
>> this does match the behavior of our scheduler

>> C4: How is the way you divided the cost of scheduling between code
>> inside and outside interrupt context likely to affect performance?

---- RATIONALE ----

>> C5: Briefly critique your design, pointing out advantages and
>> disadvantages in your design choices.  If you were to have extra
>> time to work on this part of the project, how might you choose to
>> refine or improve your design?
>> there were many options of methods to perform same computation in fixedpoint.h and we tried some of the variations and made few testcases work. 
>> If we had extra time we could understand all methods fundamentally and implement it better as in one testcase our test case failed due to 0.08 error and in other testcase where growthrate was fine but initial value was high so it failed


>> C6: The assignment explains arithmetic for fixed-point math in
>> detail, but it leaves it open to you to implement it.  Why did you
>> decide to implement it the way you did?  If you created an
>> abstraction layer for fixed-point math, that is, an abstract data
>> type and/or a set of functions or macros to manipulate fixed-point
>> numbers, why did you do so?  If not, why not?
>> we did try different combinations of set of functions but due to less time we could not understand each method.


			   SURVEY QUESTIONS
			   ================

Answering these questions is optional, but it will help us improve the
course in future quarters.  Feel free to tell us anything you
want--these questions are just to spur your thoughts.  You may also
choose to respond anonymously in the course evaluations at the end of
the quarter.

>> In your opinion, was this assignment, or any one of the three problems
>> in it, too easy or too hard?  Did it take too long or too little time?
>> third phase is really long and had more weightage than other two time distribution for each phase could have been better

>> Did you find that working on a particular part of the assignment gave
>> you greater insight into some aspect of OS design?
>> There was big learning for us in all the three phases but if there would be lille bit extra time last phase could taught much more.

>> Is there some particular fact or hint we should give students in
>> future quarters to help them solve the problems?  Conversely, did you
>> find any of our guidance to be misleading?
>> No, pintos documentation is good enough.

>> Do you have any suggestions for the TAs to more effectively assist
>> students, either for future quarters or the remaining projects?

>> Any other comments?
